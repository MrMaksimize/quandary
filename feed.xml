<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Quandary.</title>
 <link href="http://quandary.io/atom.xml" rel="self"/>
 <link href="http://quandary.io/"/>
 <updated>2017-04-28T00:38:54+00:00</updated>
 <id>http://quandary.io</id>
 <author>
   <name></name>
   <email></email>
 </author>

 
 <entry>
   <title>Why data automation matters for open data portals</title>
   <link href="http://quandary.io/why-data-automation-matters-data-portals/"/>
   <updated>2017-04-27T00:00:00+00:00</updated>
   <id>http://quandary.io/why-data-automation-matters-data-portals</id>
   <content type="html">&lt;p&gt;Be honest. When you read the words data automation you get a sudden rush of melatonin to your brain, your eyelids get heavy, and you get an uncontrollable urge to fall asleep. Don&amp;rsquo;t be ashamed; you are reacting to these words in a similar manner to 99.5% of people on the planet. Bear with me though for just a few paragraphs while I try to explain why it matters, and how we do it here at the City of San Diego.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Before we get started, let me promise to not use any of the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Mathematics (or any subset thereof)&lt;/li&gt;
&lt;li&gt;Buzzwords&lt;/li&gt;
&lt;li&gt;Tech Jargon&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;The Quick Win&lt;/h3&gt;

&lt;p&gt;One of the best case studies to make obvious the benefits of data automation is &lt;a href=&quot;http://streets.sandiego.gov&quot;&gt;StreetsSD&lt;/a&gt;. We started working on this project with the City&amp;rsquo;s Transportation and Stormwater Department (TSW). They asked us to build a map of paving projects. We got a spreadsheet of data from the department, loaded it into &lt;a href=&quot;http://carto.com&quot;&gt;our mapping tool&lt;/a&gt; and wrote some code. Boom, we had a map.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/carto_editor.jpg&quot; alt=&quot;Carto&quot;&gt;&lt;/p&gt;

&lt;h3&gt;The Ugly Loss&lt;/h3&gt;

&lt;p&gt;Most web maps, charts, and data visualizations you see in newspapers, and even those created by a lot of cities, usually stop there. That&amp;rsquo;s actually OK because a lot of these things don&amp;rsquo;t need to be updated automatically.   However, the goal of StreetsSD is to provide an up-to-date status of work to city employees and residents. Keeping the map updated is important.&lt;/p&gt;

&lt;p&gt;The typical City approach in these situations is to have someone &amp;ldquo;run a report&amp;rdquo; and upload it somewhere to update the map.  Most of the time, &amp;ldquo;running a report&amp;rdquo; actually means this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Extract data from a database, using a query (that could change, resulting in different data).&lt;/li&gt;
&lt;li&gt;Complete 1-40 manual steps in Excel to clean the data.  These steps are usually not documented anywhere and could easily vary for each run of the report.&lt;/li&gt;
&lt;li&gt;Send it or upload it somewhere.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This approach inherently has several problems:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data is inconsistent, meaning source of truth is inconsistent&lt;/li&gt;
&lt;li&gt;Bad data potentially causes bugs in the application&lt;/li&gt;
&lt;li&gt;City employees waste a HUGE amount of time&lt;/li&gt;
&lt;li&gt;People might forget to actually run the report&lt;/li&gt;
&lt;li&gt;We can&amp;rsquo;t expect someone to run a report every day (or with any kind of frequency that a continously update data source needs).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Needless to say, this sucks. And even though we&amp;rsquo;re creating a great operational tool, we&amp;rsquo;re costing people time and risking the release of wrong information.&lt;/p&gt;

&lt;p&gt;At this point, being the wise reader you are, you might be thinking that the outcome would definitely be worth the cost in the case of just one map. To which I&amp;rsquo;ll respond with:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/systemic_issue.jpg&quot; alt=&quot;Systemic issue&quot;&gt;&lt;/p&gt;

&lt;p&gt;This is not a problem with just one map. It would occur with any dataset we provide as open data on the portal, anything we build on top of those datasets, and any internal or external reports we regularly generate.  Therefore, this is a problem that needs to be solved at a systemic level.&lt;/p&gt;

&lt;h3&gt;Redemption&lt;/h3&gt;

&lt;p&gt;Our philosophy has always been to let machines do what they do best - updating data, re-running things, keeping track of things - and humans do what they do best - making those fuzzy decisions that only our brains can.&lt;/p&gt;

&lt;p&gt;We needed a flexible and extensible solution that could scale across the organization as a whole.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/sd_sources.jpg&quot; alt=&quot;CSD Data Sources&quot;&gt;&lt;/p&gt;

&lt;p&gt;We turned to an open source project called &lt;a href=&quot;https://github.com/apache/incubator-airflow/&quot;&gt;Airflow&lt;/a&gt;. It has become the tool of choice for Spotify, IFTTT, Lyft, AirBnB and many others for solving this exact set of problems.  Airflow has several advantages:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Built in Python - so it&amp;rsquo;s extensible with any of thousands of Python open-source packages&lt;/li&gt;
&lt;li&gt;Modular - new connections to different data sources are easy to write&lt;/li&gt;
&lt;li&gt;Open source with a strong community - so there&amp;rsquo;s plenty of support and continuous updates&lt;/li&gt;
&lt;li&gt;Scalable - as we need to do more and more, Airflow easily scales&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We called our Airflow deployment Poseidon because codenames are cool, San Diego is on the Ocean, and Poseidon rules the sea. Plus, we get to use images like these:
&lt;img src=&quot;/assets/images/poseidon-hero.jpg&quot; alt=&quot;Poseidon&quot;&gt;&lt;/p&gt;

&lt;p&gt;The basic idea of Poseidon is this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/simple_etl.jpg&quot; alt=&quot;Basic ETL&quot;&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Get data from a source (database, spreadsheet, map, website)&lt;/li&gt;
&lt;li&gt;Do some stuff to it (geocode it, aggregate it, clean it)&lt;/li&gt;
&lt;li&gt;Upload it (put it on the cloud that is backing our portal and a variety of other applications)&lt;/li&gt;
&lt;li&gt;Run it on a schedule (once every 5 minutes, OR once every day, OR on every odd day of the month at 3:02 PM)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Simple, right?&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re now doing this for all of our datasets (way harder to implement than explain). This means we&amp;rsquo;re also doing it for everything built on top of our data, such as StreetsSD, the portal, and various other visualizations.&lt;/p&gt;

&lt;h3&gt;The Open Sea&lt;/h3&gt;

&lt;p&gt;Now you&amp;rsquo;re probably thinking: whoop-de-doo, I&amp;rsquo;m a resident and I don&amp;rsquo;t know data, so I really don&amp;rsquo;t care that you now have automated data.&lt;/p&gt;

&lt;p&gt;We know. That&amp;rsquo;s why we pushed it further.&lt;/p&gt;

&lt;p&gt;Look back at the diagram above. Those are just dependent pieces that run in a defined cycle. What if we flipped out some of those pieces and got this?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/adv_flow_diagram.jpg&quot; alt=&quot;Adv Flow&quot;&gt;&lt;/p&gt;

&lt;p&gt;Automated data is now starting to get interesting. Because of Poseidon&amp;rsquo;s flexibility, and the fact that it&amp;rsquo;s just a bunch of coordinated tasks, we can send automatic notifications, alerts based on thresholds, and all kinds of other cool stuff that would never have been possible without automation.&lt;/p&gt;

&lt;p&gt;But if I told you what we were planning next, I&amp;rsquo;d ruin the surprise. You&amp;rsquo;ll just have to wait and see.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>A Faster Data Portal</title>
   <link href="http://quandary.io/portal-speedup/"/>
   <updated>2017-04-19T00:00:00+00:00</updated>
   <id>http://quandary.io/portal-speedup</id>
   <content type="html">&lt;p&gt;Hey San Diego!  Your open data portal just got a LOT faster!&lt;/p&gt;

&lt;p&gt;One of the reasons we wanted to &lt;a href=&quot;https://data.sandiego.gov/stories/portal-refresh&quot;&gt;run our own data portal&lt;/a&gt; is the flexibility we have to change it and add functionality.&lt;/p&gt;

&lt;p&gt;Today, we&amp;rsquo;re putting the pedal to the metal on those desires.  We initially launched the portal based on JKAN,  but with modified schemas, layouts, and branding.  Because of how fast we moved, we put off thinking about speed and performance.&lt;/p&gt;

&lt;p&gt;Since the dust settled a bit, we had a chance to do that.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;a href=&quot;https://developers.google.com/web/tools/lighthouse/&quot;&gt;Lighthouse&lt;/a&gt; is a tool developed by Google to test web pages for performance, accessibility, and more.  The first time we ran it against our portal, here&amp;rsquo;s what we got:
&lt;img src=&quot;/assets/images/lighthouse-previous.jpg&quot; alt=&quot;Click to see full report&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://theia.datasd.org.s3.amazonaws.com/data.sandiego.gov_2017-03-02_19-26-42.html&quot;&gt;See full report&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;30 out of 100, with a lot of marks against the portal due to loading speed.  Time to first paint is a metric that measures when the primary content of a page is visible. That number means it took 5.3 seconds after you navigated to the portal for anything to show up.&lt;/p&gt;

&lt;p&gt;We did badly on plenty of other metrics, including SSL encryption (HTTPS) and offline browsing.&lt;/p&gt;

&lt;p&gt;So why does this matter (besides our obsessive perfectionism)?  KissMetrics has a &lt;a href=&quot;https://blog.kissmetrics.com/loading-time/?wide=1&quot;&gt;great infographic about this&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/kissmetrics-loading.jpg&quot; alt=&quot;Loading Time&quot;&gt;&lt;/p&gt;

&lt;p&gt;In short, we were losing an estimated 25 percent of portal users because of the page loading speed.  Not good.&lt;/p&gt;

&lt;p&gt;My friend and former Code for America co-fellow &lt;a href=&quot;http://twitter.com/davidleonardii&quot;&gt;David Leonard&lt;/a&gt; (who also got me into Polymer components that the &lt;a href=&quot;https://data.sandiego.gov/stories/portal-refresh&quot;&gt;portal heavily uses&lt;/a&gt; ) helped me analyze where the bottlenecks were in our page loading time and gave me some tips about how to speed up the portal.&lt;/p&gt;

&lt;p&gt;We implemented https and service workers (for security and offline browsing and caching) and optimized how components load. The portal is now encrypted, and you can browse it offline.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m not going to go into too much detail, but you can &lt;a href=&quot;https://github.com/cityofsandiego/seaboard/pull/140&quot;&gt;see the pull request here&lt;/a&gt;.  We tested again and got a score of 96:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/lighthouse-report-final.jpg&quot; alt=&quot;New Lighthouse&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://theia.datasd.org.s3.amazonaws.com/data.sandiego.gov_2017-04-12_18-17-58.html&quot;&gt;See full report&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let me use a few buzzwords to describe what happened here, for those fond of them:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;We used an agile process to iterate on the technology underlying the performance, availability, and scalability of our portal architecture to decrease page loading speed, increase cybersecurity, and improve an already great product with enhanced user experience.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Or in English:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;We did a thing that most organizations do: we improved something we launched, because no one ever gets everything right the first time.  We&amp;rsquo;ll do it again, and again, and again. This is just the first of many changes and enhancements we will be making.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Enjoy your [faster] portal, San Diego!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Behind the Scenes of StreetsSD</title>
   <link href="http://quandary.io/streets-sd/"/>
   <updated>2016-11-01T00:00:00+00:00</updated>
   <id>http://quandary.io/streets-sd</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://streets.sandiego.gov&quot;&gt;StreetsSD&lt;/a&gt; was an interesting project us from an organizational and technical perspective.  Let&amp;rsquo;s peek behind the scenes to see how this all came together.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h1&gt;Overall Architecture&lt;/h1&gt;

&lt;h2&gt;Jekyll&lt;/h2&gt;

&lt;p&gt;Overall, &lt;a href=&quot;http://streets.sandiego.gov&quot;&gt;StreetsSD&lt;/a&gt; is a &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; site.  This allows us to avoid maintenance costs, performance issues, and complexity associated with running database-driven sites.  We host it using Github Pages for the wonderful price of $0.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/sdstreets_outline.jpg&quot; alt=&quot;Jekyll Outline&quot;&gt;&lt;/p&gt;

&lt;p&gt;Everything you see outlined in pink above is Jekyll and custom JS. We used the &lt;a href=&quot;www.sandiego.gov/communications/design/index.shtml&quot;&gt;San Diego Style Guide&lt;/a&gt; for colors and layouts.  The charts on the bottom, the layers, and the text in the explainer boxes are controlled by the &lt;a href=&quot;https://github.com/cityofsandiego/streetsSD/blob/master/src/_data/views.yml&quot;&gt;views.yml&lt;/a&gt; in the repo.&lt;/p&gt;

&lt;p&gt;All the dynamic components you see from the layers (FY14, FY15, etc) to the charts and totals are populated through custom SQL queries against data in Carto. They are constructed using the &lt;a href=&quot;https://hiddentao.com/squel/&quot;&gt;squel library&lt;/a&gt; in the &lt;a href=&quot;https://github.com/cityofsandiego/streetsSD/blob/master/src/assets/javascript/sqlBuilder.js&quot;&gt;sqlBuilder&lt;/a&gt; file.&lt;/p&gt;

&lt;p&gt;As an example, when you click on the &amp;ldquo;Work in FY-2016&amp;rdquo; layer, an event is sent that constructs and sends the query to Carto to display results on a map.  Based on the &lt;a href=&quot;https://github.com/cityofsandiego/streetsSD/blob/master/src/_data/views.yml&quot;&gt;views.yml&lt;/a&gt; file, we know that layer has WorkType and WorkByMonth charts, so one more query is constructed and sent to Carto.  After additional JS data processing, we are able to display the charts.&lt;/p&gt;

&lt;h2&gt;Carto&lt;/h2&gt;

&lt;p&gt;The interactive map itself is all Carto.  Most of the visual components (e.g. line styles, legends, hovers) are stored in Carto as well.  We don&amp;rsquo;t love that, because those should be stored in code, but we have an issue on the backlog to address it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/carto_editor.jpg&quot; alt=&quot;Carto editor&quot;&gt;&lt;/p&gt;

&lt;p&gt;The map in Carto has two &amp;ldquo;layers&amp;rdquo; - one for OCI and one for Streetwork, both based off &lt;code&gt;sdstreets_query&lt;/code&gt; table.  Carto&amp;rsquo;s model for associating layers to datasets ties them together permanently.  By having a virtual dataset that we can impose queries on, we are eliminating the tie between a dataset and a map, giving us more flexibility to flip out the underlying datasets if we need to change schemas.&lt;/p&gt;

&lt;p&gt;Then why two layers from one table?  Because OCI layers and streetwork layers have slightly different fields and labels. Carto&amp;rsquo;s interactive UI is tied to a layer, and we had to separate the two. Then, we impose the queries on the layer accordingly.  We can probably condense this to one layer using more advanced conditional logic, but we&amp;rsquo;ll stay away from that for now.&lt;/p&gt;

&lt;h2&gt;Deployment&lt;/h2&gt;

&lt;p&gt;We use the &lt;code&gt;master&lt;/code&gt; branch as the bleeding edge.  That gets deployed to a staging site continuously by CircleCI.  The &lt;code&gt;production&lt;/code&gt; branch gets deployed to the &lt;code&gt;gh-pages&lt;/code&gt; branch, which is what feeds &lt;a href=&quot;http://streets.sandiego.gov&quot;&gt;StreetsSD&lt;/a&gt;.  We get notifications about each step.&lt;/p&gt;

&lt;h2&gt;Datasets&lt;/h2&gt;

&lt;h5&gt;&lt;code&gt;cg_streets_combined&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;We created this dataset by merging the City&amp;rsquo;s official street file geographies with essential data from the City&amp;rsquo;s Pavement Management System.  Every other set of data is joined against &lt;code&gt;cg_streets_combined&lt;/code&gt; by &lt;code&gt;segment_id&lt;/code&gt; to derive the geometries and street names.&lt;/p&gt;

&lt;h5&gt;&lt;code&gt;sd_paving_datasd&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;This is the full work layer, encompassing work done from the beginning of FY14. We&amp;rsquo;ll talk about the specifics in the data delivery section.  This has no geospatial data.  As layers get selected, SQL is generated, applied to this layer, and joined against &lt;code&gt;cg_streets_combined&lt;/code&gt;.&lt;/p&gt;

&lt;h5&gt;&lt;code&gt;oci_2011_datasd&lt;/code&gt; and &lt;code&gt;oci_2015_datasd&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;These were created using historical data provided in the Pavement Management System and the new OCI numbers we received from latest run of the most recent vendor.  These also have no geospatial data.  As layers get selected, SQL is generated, applied to this layer, and joined against &lt;code&gt;cg_streets_combined&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Data Discovery&lt;/h2&gt;

&lt;p&gt;We partnered with the &lt;a href=&quot;https://www.sandiego.gov/tsw&quot;&gt;Transportation and Storm Water Department&lt;/a&gt; to build the map.  However, we quickly ran into some challenges with understanding the data, and the calculations performed for reporting.&lt;/p&gt;

&lt;p&gt;The PVM (let&amp;rsquo;s use that as the acronym for the Pavement Management System) is an application that is built on top of SQL server using queries and stored procedures.  Every month, the streets team has to update IMCAT.  IMCAT is a system the City uses to coordinate street work across departments. This way we can avoid the same segment being dug up multiple times in a short time span.  The streets team pull a report from the PVM generated by a query and a stored procedure).  Then, it&amp;rsquo;s manually cleaned in Excel (we counted 32 steps), joined with a streets shapefile, and uploaded it to IMCAT.&lt;/p&gt;

&lt;p&gt;This is where we started.  The data that gets uploaded to IMCAT has to be in a particular format with certain columns, so we couldn&amp;rsquo;t directly trace that dataset to the query running against PVM.  And we couldn&amp;rsquo;t just guess the query and match the result either - PVM has 319 tables.&lt;/p&gt;

&lt;p&gt;A few months ago, the City invested in a tool called Alation exactly for this type of use case.  We wanted to be able to maintain data catalogs and keep documentation on the data that we have, allowing data users to be better informed.  This database is the first one we connected with Alation.&lt;/p&gt;

&lt;p&gt;We built a robust query to continuously pull data.  To do this, we used Alation to trace the query the PVM application was running.  However, we had no visibility into the stored procedure.  To bypass this, we combined information from using the query, the streets team and Alation&amp;rsquo;s query logs.&lt;/p&gt;

&lt;h3&gt;Query Log&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/alation_query_log.jpg&quot; alt=&quot;Query Log&quot;&gt;&lt;/p&gt;

&lt;h3&gt;Tables&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/alation_tables.jpg&quot; alt=&quot;Tables&quot;&gt;&lt;/p&gt;

&lt;h3&gt;Table Internal View + Our Notes&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/alation_table_internal.jpg&quot; alt=&quot;Table Internal View + Our Notes&quot;&gt;&lt;/p&gt;

&lt;h3&gt;Built Query for Paving Data&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/built_query.jpg&quot; alt=&quot;Built Query for Paving Data&quot;&gt;&lt;/p&gt;

&lt;h3&gt;Built Query for Street Info&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/r9EHi&quot; alt=&quot;Built Query for Street Info&quot;&gt;&lt;/p&gt;

&lt;p&gt;Going through this process gave us an enormous amount of knowledge of street paving information, which we have documented in Alation.&lt;/p&gt;

&lt;p&gt;However, we weren&amp;rsquo;t done yet.  We still needed to build the ETL for Street Map Data, IMCAT data (because friends don&amp;rsquo;t let friends clean data over and over manually), and the &lt;code&gt;CG_STREETS_COMBINED&lt;/code&gt; file.&lt;/p&gt;

&lt;h2&gt;Data Delivery&lt;/h2&gt;

&lt;p&gt;We have two main queries that pull data without doing much cleaning.  We wanted to stay away from cleaning in SQL as a best practice.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;streets_base&lt;/code&gt; gets pulled by FME, combined with the geospatial base file, and outputs as a shapefile to S3.  Carto syncs it down from there:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/cg_fme.jpg&quot; alt=&quot;Streets Base ETL&quot;&gt;&lt;/p&gt;

&lt;p&gt;R pulls &lt;code&gt;Pavement Ex&lt;/code&gt; in using Alation&amp;rsquo;s API and the &lt;a href=&quot;https://github.com/mattwg/alation&quot;&gt;Alation R Package&lt;/a&gt;, completes the 32 manual steps the department normally has to do (with some conditional forks for IMCAT), and then outputs the &lt;code&gt;sd_paving_datasd.csv&lt;/code&gt; file into S3.  We also make sure to standardize the outgoing data according to our &lt;a href=&quot;https://datasd.gitbooks.io/open-data-implementation-update-2016/content/main/technical-guidelines.html&quot;&gt;Technical Guidelines&lt;/a&gt;.  At the same time, we output the IMCAT file to be ingested for the conflict mitigation map.&lt;/p&gt;

&lt;h2&gt;Verifying Calculations&lt;/h2&gt;

&lt;p&gt;So, how in the world do we know that our constructed SQL on the client side is doing the right thing and making the right calculations? We use R to verify that the calculations are correct by pulling the data straight from Alation, and duplicating the calculations that the SQL does on Streets Map.&lt;/p&gt;

&lt;h1&gt;What&amp;rsquo;s next?&lt;/h1&gt;

&lt;p&gt;This is an alpha project, and we plan to continue working on it.  We will work in sprints As people submit feature or bug requests, we will prioritize them according to what we think we can do during the time allotted. Critical bugs always get fixed first.&lt;/p&gt;

&lt;p&gt;Of course, we are more than open to Pull Requests.  If there is a feature you really want and we&amp;rsquo;re just unable to get to it, feel free to discuss it with us in the &lt;a href=&quot;https://github.com/cityofsandiego/streetsSD/issues&quot;&gt;issue queues&lt;/a&gt;, fork the code, and make a Pull Request.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>GIS and Spatial Joins in Tableau</title>
   <link href="http://quandary.io/tableau-gis-spatial/"/>
   <updated>2016-07-22T00:00:00+00:00</updated>
   <id>http://quandary.io/tableau-gis-spatial</id>
   <content type="html">&lt;p&gt;We own several Tableau licenses at the City of San Diego. We use it for a few things, the most visible of which is &lt;a href=&quot;http://performance.sandiego.gov&quot;&gt;PerformSD&lt;/a&gt;, which our Open Data Coordinator &lt;a href=&quot;https://www.linkedin.com/in/andrell-bower-2b576a25&quot;&gt;Andrell&lt;/a&gt; absolutely rocked.  &lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been playing around a bit with Tableau and wanted to see which Community Planning Districts have the highest density of gas stations (yes, I do ask questions like that). Tableau is not meant for heavy GIS operations, but I could see myself wanting to build a dashboard around a similar use-case.&lt;/p&gt;

&lt;h2&gt;What we have&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://data.sandiego.gov/dataset/community-planning-district-boundaries&quot;&gt;A Shapefile of Community Planning Areas from the City of SD Data Portal&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A &lt;a href=&quot;http://mrm-screen.s3.amazonaws.com/Gas_Stations.zip&quot;&gt;Shapefile of gas stations from SanGIS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Data We Need To Give Tableau&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;A CSV file of points that outline the borders of each of the polygons&lt;/li&gt;
&lt;li&gt;A CSV file of gas stations with a column that references the ID of the Community Planning District.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Convert Community Planning Districts to CSV&lt;/h2&gt;

&lt;p&gt;Tableau is not capable of working with Shapefiles at all (although that&amp;rsquo;s slated to change in Tableau 10). This means that the first thing we need to do is convert the Community Planning Districts (CPD) Shapefile to a CSV of points that outline the borders of each of the polygon.&lt;/p&gt;

&lt;p&gt;Luckily, this task already has several solutions. The easiest way is to do it using this hosted &lt;a href=&quot;%5Balteryx%20job%5D(https://gallery.alteryx.com/#!app/Tableau-Shapefile-to-Polygon-Converter/5296f89120aaf905b8e7fb48)&quot;&gt;alteryx job&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can also use this &lt;a href=&quot;https://github.com/msolbrig/TabShapeR&quot;&gt;R Script&lt;/a&gt; to get the same job done.&lt;/p&gt;

&lt;p&gt;Or, just pick up &lt;a href=&quot;http://mrm-screen.s3.amazonaws.com/ComPlan.csv&quot;&gt;the ones I have already converted&lt;/a&gt; (and don&amp;rsquo;t forget the &lt;a href=&quot;http://mrm-screen.s3.amazonaws.com/Community_Plan_SD%20(1).pdf&quot;&gt;metadata&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Now, put that file somewhere safe, and let&amp;rsquo;s go back to the community planning &lt;strong&gt;&lt;em&gt;Shapefile&lt;/em&gt;&lt;/strong&gt; for the next section.&lt;/p&gt;

&lt;p&gt;Now we need a &lt;strong&gt;A CSV file of gas stations, with a column that references the ID of the Community Planning District&lt;/strong&gt;.
To get this, we need to perform a spatial join between the CPD and the gas stations Shapefile.&lt;/p&gt;

&lt;p&gt;You can perform this operation in any GIS tool (ArcGIS, CartoDB, Python, etc). I&amp;rsquo;ve been digging R a lot lately, so that&amp;rsquo;s what we&amp;rsquo;ll use here. A spatial join is a geospatial operation to figure out which geographical objects are located within other geographical objects. In our case, we&amp;rsquo;re going to figure out which requests (points) belong in which polygons (CPD).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s do some setup We&amp;rsquo;re going to use the original CPD Shapefile we got from SANGIS, and the shapefile with all the gas stations:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;directory &amp;lt;- &amp;quot;.&amp;quot;

library(rgdal) #conatins the read/writeOGR for reading shapelies and read/writeRGDAL for reading raster data
library(rgeos) # neccessary for ggplot2::fortify.sp(); serves as a replacement for gpclib
library(maptools) #Contains the overlay command
library(dplyr) # For data magic

setwd(directory)

# Lat / Lon projection string.
latlon &amp;lt;- &amp;quot;+init=epsg:4326&amp;quot;

gasStations &amp;lt;- readOGR(&amp;quot;./data/Gas_Stations&amp;quot;, 
                       layer = &amp;quot;GAS_STATIONS&amp;quot;)

com_plan &amp;lt;- readOGR(&amp;quot;./data/Community_Plan_SD&amp;quot;, 
                    layer = &amp;quot;Community_Plan_SD&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, let&amp;rsquo;s execute the spatial join in R&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;gasStationsCPD &amp;lt;- over(gasStations, com_plan)
# Since it&amp;#39;s really based by rownumber, let&amp;#39;s do a safe join of the new 
# gas station data, and the gas stations belonging in each community planning
# district.
gasStations@data &amp;lt;- as.data.frame(bind_cols(gasStations@data, gasStationsCPD))

# How many match?
nMatches &amp;lt;- nrow(gasStationsCPD[complete.cases(gasStationsCPD), ])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will give us a dataframe with 787 rows, or the number of rows in our gas stations Shapefile. The blank rows simply don&amp;rsquo;t match a community planning district. 291 rows are not blank, meaning 291 out of 787 gas stations are located in a community planning district in San Diego. Since our goal here is to do as much data manipulation in Tableau as possible to allow for maximum end-user flexibility, we will leave the task of filtering out the blank rows to Tableau.&lt;/p&gt;

&lt;p&gt;We still need to give Tableau a CSV with lat/longs, and currently gasStationsCPD is a SpatialPointsDataFrame. Let&amp;rsquo;s make a CSV.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# First, let&amp;#39;s adjust the coordinates to lat/long
gsDF &amp;lt;- spTransform(gasStations, CRS(latlon))

gsDF &amp;lt;- as.data.frame(gsDF) %&amp;gt;%
    rename(latitude = coords.x1, longitude = coords.x2)

write.csv(gsDF, file = &amp;quot;./data/tableau_out/gas_stations.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will give us our gas station file with a column referencing a Community Planning District, and that column will be populated if the gas station is located within one.&lt;/p&gt;

&lt;h2&gt;Putting it all together&lt;/h2&gt;

&lt;p&gt;Now, we have our CSV file with a set of points that outline the edges of the Community Planning District polygons and our CSV file with Gas Stations, their lat/longs, and a reference to which community district within which they are located.
To start building in Tableau, we need to add our data sources first. Make sure to put ComPlan.csv and gas_stations.csv in the same folder. For some reason, Tableau likes it better that way.&lt;/p&gt;

&lt;p&gt;Then, drag in the ComPlan.csv file, followed by the gas stations csv:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/koYwj&quot; alt=&quot;Tableau1&quot;&gt;&lt;/p&gt;

&lt;p&gt;Tableau will pop up the fields for you to join the data. Select the match on CPNAME, and now they&amp;rsquo;re joined.  &lt;/p&gt;

&lt;p&gt;Next, let&amp;rsquo;s do some mapping!&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Command- (or control) click on Lattitude and Longitude measures under Com Plan&lt;/li&gt;
&lt;li&gt;Click the map under Show Me&lt;/li&gt;
&lt;li&gt;Drag CPNAME dimension from ComPlan under marks&lt;/li&gt;
&lt;li&gt;Drag Polygon ID dimension from ComPlan under marks&lt;/li&gt;
&lt;li&gt;Change Mark Type to Polygon&lt;/li&gt;
&lt;li&gt;Drag Point ID dimension from ComPlan under marks&lt;/li&gt;
&lt;li&gt;Drag Number of Records measure from Gas Stations to the color box&lt;/li&gt;
&lt;li&gt;Drag CPNAME dimension from ComPlan under marks.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We have a map of community planning districts colored by the density of gas stations in each!&lt;/p&gt;

&lt;p&gt;We can also add a filter:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/Up4JJ&quot; alt=&quot;Tableau2&quot;&gt;&lt;/p&gt;

&lt;p&gt;This lets us filter by the number of gas stations in a Community Planning District.&lt;/p&gt;

&lt;h2&gt;The Result&lt;/h2&gt;

&lt;p&gt;You can find the &lt;a href=&quot;https://public.tableau.com/views/SDGasStationsbyCommunityPlanningDistrict/Sheet5?:embed=y&amp;amp;:display_count=yes&amp;amp;:showTabs=y&quot;&gt;published interactive visualization on Tableau Public&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://public.tableau.com/views/SDGasStationsbyCommunityPlanningDistrict/Sheet5?:embed=y&amp;:display_count=yes&amp;:showTabs=y&quot; title = &quot;SD Gas Stations by Community Planning District&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://mrm-screen.s3.amazonaws.com/SD_Gas_Stations_by_Community_Planning_District_-_MrMaksimize__Tableau_Public_2016-07-25_10-51-38.png&quot; alt = &quot;SD Gas Stations by Community Planning District&quot;&gt;&lt;/img&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;What&amp;rsquo;s Next?&lt;/h2&gt;

&lt;p&gt;The gas_stations.csv file has plenty of interesting attributes, so it&amp;rsquo;s time to let your imagination run wild.  By adding that simple column of community planning district id to the CSV file of gas stations, we have given ourselves to do all kinds of filtering by the community planning district.&lt;/p&gt;

&lt;p&gt;You can pick up the relevant code, Tableau workbook and links to files in the &lt;a href=&quot;https://github.com/MrMaksimize/RTableauGasStationsExperiment&quot;&gt;Github Repo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you find something wrong or disagree with me, you know what to do :)   &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What Is A Dataset? A Delicious Explanation.</title>
   <link href="http://quandary.io/what-is-a-dataset/"/>
   <updated>2016-04-20T00:00:00+00:00</updated>
   <id>http://quandary.io/what-is-a-dataset</id>
   <content type="html">&lt;p&gt;If you work with data, or interact with people who do, you have inevitably heard the word &amp;ldquo;dataset&amp;rdquo;.  It&amp;rsquo;s one of those jargon-y words that gets thrown around, and people are somehow supposed to know what it means. It&amp;rsquo;s like when you go to the doctor, and he tells you that you will need &amp;ldquo;labrum repair&amp;rdquo;, and you feel stupid asking what a labrum is.  &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Data_set&quot;&gt;Wikipedia&amp;rsquo;s Definition of a Dataset&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Most commonly a data set corresponds to the contents of a single
database table, or a single statistical data matrix, where every column
of the table represents a particular variable, and each row corresponds
to a given member of the data set in question.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And &lt;a href=&quot;http://www.data.gov/glossary&quot;&gt;data.gov&amp;rsquo;s definiton&lt;/a&gt; is:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A dataset is an organized collection of data. The most basic
representation of a dataset is data elements presented in tabular form.
Each column represents a particular variable. Each row corresponds to a
given value of that column’s variable. A dataset may also present
information in a variety of non-tabular formats, such as an extended mark
-up language (XML) file, a geospatial data file, or an image file.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nothing is incorrect about these definitions, but they tend to miscommunicate and under-explain what a dataset is. This causes a lot of confusion and frustration in the government open data community (and probably other communities as well). People end up thinking that there are datasets laying around on a shelf somewhere &amp;ndash; that it&amp;rsquo;s a finite, well-defined thing that a city employee can just grab and publish.  Sometimes, it&amp;rsquo;s true.  However, more often than not, a dataset is more like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/AZ3WU&quot; alt=&quot;Cookies&quot;&gt;&lt;/p&gt;

&lt;p&gt;There are two properties that every dataset has that are critical to how useful it is &amp;ndash; &lt;strong&gt;format&lt;/strong&gt; and &lt;strong&gt;structure&lt;/strong&gt;.  &lt;/p&gt;

&lt;h2&gt;Format&lt;/h2&gt;

&lt;p&gt;Format is fairly straightforward.  In order for a dataset to be used by as many people as possible, it has to be open and machine readable. This is just a primer - I&amp;rsquo;ll go into more detail in a different post. &lt;/p&gt;

&lt;h3&gt;Open&lt;/h3&gt;

&lt;p&gt;Open formats are those that can be read by a simple text editor.  For example, CSV files - a common format for tabular data can be opened in Notepad.  They will be hard to read by a human, but it&amp;rsquo;ll work. They can also be opened in Excel and plenty of languages have CSV parsers.  &lt;/p&gt;

&lt;p&gt;However, the sister of the CSV file - the Excel file can &lt;strong&gt;only&lt;/strong&gt; be opened in Excel.  That means that if I want to look at your file, I have to give Microsoft some serious $$ for Microsoft Office.   &lt;/p&gt;

&lt;h3&gt;Machine Readable&lt;/h3&gt;

&lt;p&gt;The other aspect of an open dataset is that it&amp;rsquo;s machine readable.  This ties in with &amp;ldquo;open&amp;rdquo; - since many more languages and libraries can read formats not copyrighted by a vendor.  But this also means structured in a predictable manner.  For example, a PDF file is not machine readable because it&amp;rsquo;s digital paper - and breaking down the structure of a PDF is really hard for a program that can only deal with structured data - the format is closed and copyrighted, and also extremely opaque.&lt;/p&gt;

&lt;h2&gt;Structure&lt;/h2&gt;

&lt;p&gt;Structure is a lot more difficult to get right than format. For the sake of this post (and to keep you awake), we&amp;rsquo;ll talk only about tabular data (data that lives in rows and columns).  There are other types of data though, such as GIS (mapping) data, XML / JSON (nested data), and several others.  &lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s step back and take a look at a database (or the dough blob).   We&amp;rsquo;ll keep NoSQL databases out of this for simplicity and only focus on the old-school relational databases.  What does a database look like?&lt;/p&gt;

&lt;p&gt;Contrary to what Hollywood would like us to think, this is not a database:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://c2.staticflickr.com/6/5142/5577388841_97e1280796_b.jpg&quot; width=&quot;100%&quot;/ alt=&quot;Not A Database&quot;&gt;.  &lt;/p&gt;

&lt;p&gt;A relational database isn&amp;rsquo;t really that exciting - it&amp;rsquo;s just a collection of tables (sorry, I tried, but relating this to cookies is hard):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/MkaCS&quot; alt=&quot;A Database&quot;&gt;&lt;/p&gt;

&lt;p&gt;These tables contain a variety of columns. Invariably, one or more of these columns is going to have a set of values that relates to a set of values in another table.  That&amp;rsquo;s what makes a database relational and also what gives the technology so much power and flexibility.  It&amp;rsquo;s like dough - you can shape it, mold it, cut it and change its shape as much as you want to fit your cookie idea.  &lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Dough is Flexible - You can make cookies or cupcakes&quot; src=&quot;http://take.ms/9eaVo&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look a more concrete example:  &lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s say you have a company that sells widgets.  You keep track of your customers, and you keep track of the widgets you sell.  Let&amp;rsquo;s imagine a very simple database with just three tables:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/y0Nyv&quot; alt=&quot;Simple Three Table Database&quot;&gt;&lt;/p&gt;

&lt;p&gt;There is one table to keep information on your customers, another one to keep track of the widgets you have, and a table that keeps track of the orders - where the customers bought the widgets. For the sake of simplicity, there is only one customer per order and one widget per order.  &lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at some example data in this type of structure and examine some points below: &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/OdQsB&quot; alt=&quot;Sample Widget Data&quot;&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We can see that each table has an ID column. This is called a &lt;strong&gt;primary key&lt;/strong&gt; and is used for the database to differentiate each record in that specific table.  A lot of times it corresponds to a row number.&lt;/li&gt;
&lt;li&gt;In the orders table, we can see that each order has its own ID but also references the ID of the widget sold and the customer to whom it was sold.&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So with the following example, what are some datasets we can generate?  There are many options:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We can get 3 datasets already just by using the tables themselves. So, there will be a customers dataset, a widgets dataset, and an orders dataset. However, the orders dataset will be pretty useless, since it references IDs only relevant in the context of the other two tables.&lt;br&gt;&lt;/li&gt;
&lt;li&gt;We can get a list of only those customers who have purchased a widget.&lt;br&gt;&lt;/li&gt;
&lt;li&gt;We can get a list of customers who purchased a widget and live in Chicago.&lt;br&gt;&lt;/li&gt;
&lt;li&gt;We can get a list of all the customers regardless of whether they have purchased a widget.&lt;br&gt;&lt;/li&gt;
&lt;li&gt;We can get a list of customers, the widget they each purchased, the model of the widget, and how much the widget costs.&lt;br&gt;&lt;/li&gt;
&lt;li&gt;We can get a list of widgets and which customers purchased them.&lt;br&gt;&lt;/li&gt;
&lt;li&gt;Or a list of widgets and in which city they were purchased.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We get these datasets by using SQL, a database query language, and what you see above is not an exhaustive list: there are many other alternatives.  In addition, due to data schema changes, process changes and technology changes, data after a certain date may not be valid or may not mean the same thing.  For example, up until our widget company changed their process in 2011, the &amp;ldquo;city&amp;rdquo; column in the customer table indicated the city in which the customer was born, not where he or she lived.  &lt;/p&gt;

&lt;p&gt;This complexity is present in our simple fake database of just three tables, but modern relational databases have upwards of 100, often thousands of tables. There are also plenty of caveats in how they&amp;rsquo;re named, how relations are structured, and what type of queries make sense. Plus, writing the queries is no easy task. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/XDzwb&quot; alt=&quot;So Many Choices&quot;&gt; &lt;/p&gt;

&lt;h2&gt;Some Clarification&lt;/h2&gt;

&lt;p&gt;I want to take a moment to clarify here - I&amp;rsquo;m not saying that every dataset is hard to create.  Sometimes it&amp;rsquo;s as easy as grabbing an Excel file from the desktop.  But even then, it&amp;rsquo;s still necessary to make sure that there are no sensitive data in there, such as someone&amp;rsquo;s phone number.  &lt;/p&gt;

&lt;p&gt;I also haven&amp;rsquo;t touched on things like aggregation and making sure that we generate data that fits the &lt;a href=&quot;http://vita.had.co.nz/papers/tidy-data.pdf&quot;&gt;Tidy Data Spec&lt;/a&gt; so that it&amp;rsquo;s prime for analysis.&lt;/p&gt;

&lt;p&gt;How do &lt;strong&gt;&lt;em&gt;you&lt;/em&gt;&lt;/strong&gt; define a dataset?  &lt;/p&gt;

&lt;p&gt;I hope I was able to show you that it&amp;rsquo;s not all cut and dry.  &lt;/p&gt;

&lt;p&gt;The next time you go and ask someone for a dataset, bring them a box of cookies just in case. Fulfilling your request may involve a lot of hard work. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What I Learned In One Year as CDO of San Diego</title>
   <link href="http://quandary.io/what-i-learned-one-year-cdo/"/>
   <updated>2016-01-11T00:00:00+00:00</updated>
   <id>http://quandary.io/what-i-learned-one-year-cdo</id>
   <content type="html">&lt;p&gt;Fairly recently, I celebrated my 1 year anniversary of being with the city of San Diego as the Chief Data Officer. Naturally, I’ve been reflecting on my first year in government, and one of the things that strikes me the most is the amount of things that I learned. &lt;/p&gt;

&lt;p&gt;Some things I learned on my own &amp;ndash; in many cases I invested in supplementary learning in order to succeed.  Others I can directly attribute to conversations with my boss, Almis, my teammates in &lt;a href=&quot;http://sandiego.gov/pad&quot;&gt;Performance and Analytics&lt;/a&gt;, the City’s IT staff, and so many others that if I list them all, this would be a spreadsheet, not a blog post. &lt;/p&gt;

&lt;p&gt;To be completely honest &amp;ndash; I had my hesitations about taking a local government job.  I was worried I wouldn’t advance my technological skill, and potentially lose many of the marketable skills I possess.  However, looking back on this year, taking a government job has proven to be one of the smartest and challenging things I’ve ever done.  There is no other place I can think of that would push me so far out of my comfort zone, in so many different directions, while providing me the help and support to succeed.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2&gt;Technical Skills&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-screen.s3.amazonaws.com/FkfrZF40zVTufzhDi4YTumNGu6LEAPRoMSllrUPmNyU.jpg&quot; alt=&quot;Tools&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tools for the Job.&lt;/strong&gt; I’m proud to say that I have a very wide expertise in a diverse range of technologies, languages and stacks.  I walked into this job with a preconception that my large toolbox can solve a variety of problems quickly.  Instead, I quickly realized that in order to use my toolbox effectively, I needed to understand all the intricate non-technological complexities such as strategy, culture, processes, and even words used to describe things.  What&amp;rsquo;s more, I had to expand my toolbox with more open source and not-so-open-source tools.  The City is a large enterprise, and not everything can be solved by cloning a repo or a $30 a month subscription. This intangible skill of understanding City operations and figuring out the details of how to apply the correct technology has been one of my biggest learnings this year.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;R Language.&lt;/strong&gt; This past year, I learned the &lt;a href=&quot;https://www.r-project.org/&quot;&gt;R language&lt;/a&gt; - the first data-focused language I’ve used. In addition to learning the language itself, I learned how to communicate research and data analysis through detailed and reproducible reports.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Google Apps Script.&lt;/strong&gt; I wouldn’t necessarily say that I &amp;ldquo;learned&amp;rdquo; it, but I definitely became much more familiar with the capacities of Apps Script for handling large amounts of documents programmatically.  This code ran a lot of our initial data inventory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GIS.&lt;/strong&gt; Through our wonderful GIS manager, &lt;a href=&quot;https://www.arcgis.com/features/&quot;&gt;ArcGIS&lt;/a&gt; and &lt;a href=&quot;https://cartodb.com/&quot;&gt;CartoDB&lt;/a&gt;, I became much more familiar with GIS operations and concepts. However, I would place myself very far from expert level.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/ijqAB&quot; alt=&quot;Cyber&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cybersecurity.&lt;/strong&gt; Something we often don’t think about when it comes to cities is the massive need for cybersecurity. Cities are constantly getting hit and need robust and well-managed cybersecurity programs in place. I have become good friends with the CISO and the Cyber team in San Diego and learned quite a bit about their strategies, technologies and methods.  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Enterprise IT.&lt;/strong&gt; We often like to make fun of &amp;ldquo;antiquated&amp;rdquo; City technology like SAP and Oracle. However, these are still massive companies running multi-million dollar projects and are not going away soon. I’ve worked quite a bit with IT to understand the ecosystems and infrastructure that manage these large datastores within the City.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;So Many Datastores.&lt;/strong&gt; This brings me to the diversity of datastores within the City. From a technical level, I’ve been exposed to a variety of SAP, Oracle, Microsoft and ESRI products. This year, I’ve had lots of technology land on my plate. Even though this isn’t very sexy, going down the journey of learning these technologies has been a blast.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Networks.&lt;/strong&gt; Working with IT to understand the City’s networks, I’ve learned a ton about the City’s DNS architecture, networks, configuration management, desktop management, Active Directory and so much more.  The City also does a lot of cool things, such as producing its own TV station.  We even have a truck that can pull up to a location and provide wi-fi and cellular communications in emergencies.&lt;/p&gt;

&lt;h2&gt;Strategic Skills&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Technological Interventions.&lt;/strong&gt; Operational improvement opportunities that would otherwise remain hidden often surface when a public-facing data visualization or analysis is on the horizon. It’s a fortunate thing I work in a department that cares to fix those as well.  I have also begun to explore how to use what I call &amp;ldquo;technological interventions&amp;rdquo; strategically to discover problems in processes of collecting, generating and sharing data across systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Communicating with Executives.&lt;/strong&gt; In the course of my work, I had to learn how to work with elected officials and high level executives. I learned how to properly scale the level of detail while explaining complex technical concepts and challenges. Scaling detail is extremely important because it’s often necessary for me to walk a fine line between confusing the person I’m talking to and providing them with the amount of information necessary for them to make a decision.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/kN0t2&quot; alt=&quot;Boss&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Managing up&lt;/strong&gt; became very important as well. My boss is extremely flexible and understanding, but oftentimes he doesn’t need to (or really want to) be deeply involved in the details of my decision making and thought processes: he empowers me, which is both scary and great.  It makes sense too: he really doesn’t need to know all the variables I’m weighing when deciding on a technology or working on a project.  By managing up, I’m able to keep his expectations at the proper levels while giving myself a good amount of flexibility to change my mind.  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Managing Meetings.&lt;/strong&gt; Government is notorious for having a meeting-loving culture. I learned how to manage and limit the amount of meetings that I end up involved with, while making sure that I maintain relationships and remain apprised of what’s going on.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Evaluating technology&lt;/strong&gt; in the context of the City, or rather in the context of enterprise IT requires weighing many factors.  I learned a lot about how to evaluate technological solutions in this type of context.  How does a piece of software fit into the larger IT roadmap?  What do the service level agreements and maintenance options look like?  Is it better to get Open Source or proprietary solutions?  How will this impact the City’s cybersecurity risk exposure?  What is the price point and what are the related procurement rules dictating the process we’ll go through?  All these factors weigh into evaluating a piece of software in a large IT environment.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hacking People, no USB cable required&lt;/strong&gt;.  No, really, I learned how to get 65 non-technical people who have other jobs to answer my questions about what data they have, make it extremely easy for them to do so, and not have them hate you afterwards.  Oh, and only have one large meeting through that whole process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Shipping.&lt;/strong&gt; I learned quite a bit about how to balance the inherent complexity of being a CDO of a massive organization with designing the correct architecture, building a sustainable infrastructure, and well, shipping.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;More Shipping.&lt;/strong&gt; Elaborating on the point above, I tend to lean more on the perfectionist side of being a programmer.  I’ll think deeply about choosing the right framework, picking the right stack and overall making sure I’m doing things &amp;ldquo;right&amp;rdquo;.  In the past, this caused unnecessary slowdowns in some of my projects.  However, in this past year, when I had a much smaller part of my time to be a developer, I noticed myself being able to adjust my “perfectionist” strategies towards a strategy where I just write some code, and refactor if I’m going to keep it.  It seems like a minor shift, but being able to accept imperfection in my own code has allowed me to prototype a lot more, a lot faster.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Technology Perception Gaps.&lt;/strong&gt; I’ve learned to see and more clearly understand the gap between the public’s perception of Open Data and the technology and effort needed to deliver data that isn’t just open, but is accurate and complete.  While this gap exists in the Open Data space, I would argue that this gap exists in many perceptions that the public has about City IT.  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learning from Private Sector.&lt;/strong&gt; I often seek out sources of inspiration for my work by attending private sector events, training sessions, and simply communicating with technology communities that I’m used to working with. I also love to interact with other governments to see how they’re doing things. However, not everything that works in the private sector works in the government space. I learned quite a bit about how to learn (and not learn) from the private sector and relate it to our work at the City.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Open Data Activation Points.&lt;/strong&gt; I’ve begun to see &amp;ldquo;Activation Points&amp;rdquo; for open data – where opening data ties in smooth as butter with a current City initiative. (Sustainability, Performance Management, Public Records Act Requests (PRA)).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Building and running a data team&lt;/strong&gt; is a leadership, strategic and tactical challenge.  I have learned, and am still learning a lot about how to build one, ramp it up, and align the correct pieces for delivery.&lt;/p&gt;

&lt;h2&gt;Departments / City Operations&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-screen.s3.amazonaws.com/CDzAoLRdhebNHFZ8wzpFfVS4WQHoGXNHwd3mwCq4ZRg.jpg&quot; alt=&quot;LifeGuard&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lifeguards.&lt;/strong&gt; I learned a ton about what lifeguards do, how they operate, and some of the technological challenges of the job.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Police.&lt;/strong&gt; I explored how the City’s Police Department works with bar owners in the Gaslamp to create a safer area, handle barbreak (when all the bars let out) and prevent crime.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-screen.s3.amazonaws.com/blGfuh6Z8Li39Vgz78R0GeNf69cEAlFB3ddcR1XoOSY.jpg&quot; alt=&quot;BarBreak&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Street Work.&lt;/strong&gt; I know much more about how the City’s street work gets done, and the different types of repair jobs.  I was also surprised to find out that the City does a proactive job of making sure that money isn’t wasted by having the same street repaved multiple times in a short period.  Because of various responsibilities different departments have when it comes to digging up a street, they do a lot of work to coordinate the timing of the construction.  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PRAs.&lt;/strong&gt; Many people outside of government or journalism don’t even know about PRAs.  Working with the City’s PRA coordinator, I’ve learned a ton about the legalities of the process and how they work within the City.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Emergency Response.&lt;/strong&gt; Do you know what to do if an earthquake hits? Your City officials do - they often conduct training and simulations for different disaster scenarios.  I got to explore this as well. They have a &amp;ldquo;situation room&amp;rdquo; in one of the buildings, stocked with food and computers. Learning about the City’s ways of managing disaster has been nothing short of amazing.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-screen.s3.amazonaws.com/n7fTr2uXzd7lHJZDRClDslP2Pqgv5l7Jc9mxPkwgykU.jpg&quot; alt=&quot;Crap&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Crap.&lt;/strong&gt; I learned all about what happens to the crap we flush. It’s actually way more interesting than it sounds. This is a story that encompasses poop, energy generation, earplugs, and seals.  Where did I learn about this?  The &lt;a href=&quot;http://www.sandiego.gov/mwwd/facilities/ptloma/&quot;&gt;Point Loma Wastewater Treatment Plant&lt;/a&gt; - an automated plant that serves 2.2 million residents run by only 50 people.&lt;/p&gt;

&lt;h2&gt;Communications and Community&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Talking Louder.&lt;/strong&gt; I have been a quiet and shy speaker for most of my life.  However, when I started this job, I quickly learned (with Almis’ advice) that I needed to overcome that.  I took several months of improv classes (which were a blast) and while I’m still working up to having a booming voice, I can definitely say that I haven’t been asked to speak louder in a long time.  &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-screen.s3.amazonaws.com/RhYlSZwxJ38x_YJ96g3EvW4ivMzPpFbYuOdf_twbQyY.jpg&quot; alt=&quot;Press&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Press.&lt;/strong&gt; I learned a lot about how to talk and work with the press. It was really fascinating to learn the role of press in government and how the City handles communication with journalists.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Public Speaking.&lt;/strong&gt; I still need to tally up how much public speaking I’ve done this year, but it was definitely more than I’ve ever done in my life. There’s plenty of things I learned in this arena this year, such as structuring effective presentations, storytelling, and other skills.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://take.ms/qrrSK&quot; alt=&quot;Ignite&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ignite Talk.&lt;/strong&gt; I gave an &lt;a href=&quot;https://www.youtube.com/watch?v=IvABvAM11XM&quot;&gt;Ignite Talk&lt;/a&gt; about the data flowing through a City block.  Obviously, I learned how to give an Ignite talk, which in itself is a very difficult, but ultimately rewarding experience.  But through that process I discovered how much I knew about the data flowing through cities &amp;ndash; and how much I have yet to learn.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reporting to Council.&lt;/strong&gt; I also got to prepare a report to the City council and present it - a learning experience in and of itself. As a side note, as part of getting the &lt;a href=&quot;https://datasd.gitbooks.io/council_report/&quot;&gt;Open Data Implementation Update&lt;/a&gt; ready for council, I ended up making a &lt;a href=&quot;https://github.com/GitbookIO/gitbook/pull/813&quot;&gt;pull request&lt;/a&gt; to a major open-source software project.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Community Building.&lt;/strong&gt; I always felt that in order for Open Data to be successful in San Diego, we needed to have a strong Civic Tech community. Before, this was far from the case. Now, we’re much closer – I’ve learned a ton about how to put the right people in the right place to get the community moving. I&amp;rsquo;m very excited about the &lt;a href=&quot;https://github.com/opensandiego&quot;&gt;work&lt;/a&gt; &lt;a href=&quot;http://www.meetup.com/Open-San-Diego/&quot;&gt;Open San Diego&lt;/a&gt; has accomplished in the past year.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-random.s3.amazonaws.com/dz/2015-05-19%2018.03.23.jpg&quot; alt=&quot;Meters&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Connecting Geeks to Government.&lt;/strong&gt; In addition to building the community, I’ve always strongly felt there was a missing connection between CfA Brigade members, residents, and City employees. Bringing various people in the City-people I greatly respect-to talk about what they do with the brigade has been an invaluable learning experience both for me, the brigade, and the employees. I think we often forget how freaking cool City government can be.&lt;/p&gt;

&lt;h2&gt;Surprises&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-screen.s3.amazonaws.com/L3m6_FmcRUPXoQ02fttrdGrayRX_GPPVFY4XZHKmSHs.jpg&quot; alt=&quot;Surprises&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Passion.&lt;/strong&gt; I was surprised about how I feel after a conversation with a City employee (not everyone of course, but so many of them). For example, I talked to someone about parking meters and was inspired and excited after that conversation. It’s amazing to see people that have just as much passion for their craft as many programmers do for theirs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data geeks.&lt;/strong&gt; I’m not talking &amp;ldquo;analysts&amp;rdquo;. I’m talking about the people that geek out over Excel macros and SQL queries. Or GIS. There aren’t many of them in the City, but they’re there. It takes a while to find them too. But once you do – wow – they can teach you so much and are such a pleasure to work with.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data Literacy.&lt;/strong&gt; How people think about what data is, how they define data, how they understand KPIs and metrics has been a challenge that I have enjoyed learning about and solving.  &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-screen.s3.amazonaws.com/UFqXeLkzS_tU-kcuoIENvcWWKXtVxA4o-eKzR1RkTQs.jpg&quot; alt=&quot;Clifton&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Open Doors.&lt;/strong&gt; Many people already recognize the potential for decreased workload and better communications that opening data carries. I was extremely surprised how many people approached me, excited for their data to be opened up.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State of The City.&lt;/strong&gt; Did you know that just like the President does an annual State of the Union, many mayors do a State of the City Address? I didn’t. It was amazing to see it get put together, how many people work on it, and some of the things I learned by attending.  Also it was pretty sweet to get a shout from Mayor Faulconer just a month into the job. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dependencies.&lt;/strong&gt; I noticed a distinct difference between how I’m used to working to how I have to work in the City.  In my previous jobs as a software developer and architect, I could generally forge my own path and minimize a lot of critical reliance on other people.  In the City I feel highly leveraged &amp;ndash; oftentimes the support of others is absolutely critical.  I haven’t thought too far down this path yet, but will be exploring it.  &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-screen.s3.amazonaws.com/G1y5CL8dOxX9UY-xN9VyE0e_ELxvtxgN0VM0NWr-Ly8.jpg&quot; alt=&quot;Delegation Pres&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Internationalizing.&lt;/strong&gt; I’ve had the opportunity to present to Macedonian and Philippine delegations. In the Mayor’s conference room. About Open Data. Nuff said.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CNAMEs.&lt;/strong&gt; When we were launching OpenGov - our budget tool, I thought it would be great for us to map it to &lt;a href=&quot;http://budget.sandiego.gov&quot;&gt;http://budget.sandiego.gov&lt;/a&gt;.  The saga that happened while I was trying to do something fairly simple &amp;ndash; just map a CNAME to a domain &amp;ndash; was a journey I will never forget.  &lt;/p&gt;

&lt;h2&gt;Random&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Vendors.&lt;/strong&gt; Working with vendors has been good, bad and ugly. There is so much to write about here: from evaluating proposals and negotiating; to the &amp;ldquo;classifications&amp;rdquo; of vendors I’ve begun to unofficially define based on what they sell and how they sell it; to how they can have better strategy and products. We have developed numerous ways to streamline the process of vendor pitches by having a standard method and questions that they have to use to get in touch with us. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;City Awards and Competitions&lt;/strong&gt;, run by various think tanks and vendors are also something I’ve been reflecting on lately. While having some value, a lot of times they appear to be run more for the benefit of a vendor looking to score more government contracting opportunities.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Time Management.&lt;/strong&gt; I’ve had to implement rigid time management methodologies because of the amount of noise often coming on my plate. While this may seem like an underwhelming learned lesson, I would say this is what has allowed me to become the most effective.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Project Management.&lt;/strong&gt; When you have an organization of 11,000 people, IT projects quickly start to look a little different. Sometimes there’s a legitimate need for a strong project management methodology. Sometimes there isn’t. I’ve learned quite a bit about how the City runs large IT projects&amp;ndash;and small ones.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hiring.&lt;/strong&gt; As part of hiring my first employee, I got to be on the hiring side, all the way through the recruitment process. I ended up taking notes for myself, for, you know, the next time I have to look for a job. It was super valuable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://mrm-screen.s3.amazonaws.com/yNAvvjKDqmoQ9kuo6t1zliN2FESeAWh8XHr3y1tIrTA.jpg&quot; alt=&quot;Sup Academy&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Supervising.&lt;/strong&gt; Because I was getting a new employee, I had to go through the City’s &amp;ldquo;Supervisor’s Academy&amp;rdquo;. This was a seven day course, outlining everything from City support for employees experiencing various issues, to ethics, to leadership. I found it extremely useful and learned a ton about, well, being a good supervisor.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ethics.&lt;/strong&gt; I learned a bit of how ethics and campaign finance work in the City context, and had some fairly interesting conversations with the Ethics commission, including one about the limits on what expenses can and cannot be covered by a conference organizer who invites me to present at a conference.&lt;/p&gt;

&lt;p&gt;In summarizing my experience at the City, the main thing that surprised me this year was how much I was pushed out of my boundaries, and how many things I’ve done that I never thought I could or would do. Everything from learning a new language, doing an Ignite talk, to learning how to be a better communicator and leader, I can attribute to being a City employee in one way or another. Now that year 1 is behind me, I’m stoked for year 2.&lt;/p&gt;
</content>
 </entry>
 

</feed>
